<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 4 Cross-validation | Targeted Machine Learning with Big Data in the tlverse</title>
<meta name="author" content="Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips">
<meta name="description" content="Ivana Malenica Based on the origami R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips. Updated: 2021-08-16 Learning Objectives By the end of this chapter you will be able...">
<meta name="generator" content="bookdown 0.23.1 with bs4_book()">
<meta property="og:title" content="Chapter 4 Cross-validation | Targeted Machine Learning with Big Data in the tlverse">
<meta property="og:type" content="book">
<meta property="og:url" content="https://tlverse.org/tmlcimx2021-workshop/origami.html">
<meta property="og:description" content="Ivana Malenica Based on the origami R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips. Updated: 2021-08-16 Learning Objectives By the end of this chapter you will be able...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 4 Cross-validation | Targeted Machine Learning with Big Data in the tlverse">
<meta name="twitter:description" content="Ivana Malenica Based on the origami R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips. Updated: 2021-08-16 Learning Objectives By the end of this chapter you will be able...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.9002/transition.js"></script><script src="libs/bs3compat-0.2.5.9002/tabs.js"></script><script src="libs/bs3compat-0.2.5.9002/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script><link href="libs/vis-4.20.1/vis.css" rel="stylesheet">
<script src="libs/vis-4.20.1/vis.min.js"></script><script src="libs/visNetwork-binding-2.0.9/visNetwork.js"></script>
</head>
<body>
<span class="math inline">
  \(\DeclareMathOperator{\expit}{expit}\)
  \(\DeclareMathOperator{\logit}{logit}\)
  \(\DeclareMathOperator*{\argmin}{\arg\!\min}\)
  \(\newcommand{\indep}{\perp\!\!\!\perp}\)
  \(\newcommand{\coloneqq}{\mathrel{=}}\)
  \(\newcommand{\R}{\mathbb{R}}\)
  \(\newcommand{\E}{\mathbb{E}}\)
  \(\newcommand{\M}{\mathcal{M}}\)
  \(\renewcommand{\P}{\mathbb{P}}\)
  \(\newcommand{\I}{\mathbb{I}}\)
  \(\newcommand{\1}{\mathbbm{1}}\)
  </span>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="A Short Course for the Public Health and Epidemiology Program (PASPE) at the National Institute of Public Health in Mexico">Targeted Machine Learning with Big Data in the <code>tlverse</code></a>:
        <small class="text-muted">A Short Course for the Public Health and Epidemiology Program (PASPE) at the National Institute of Public Health in Mexico</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Information</a></li>
<li><a class="" href="motivation.html">Motivation</a></li>
<li><a class="" href="tlverse.html"><span class="header-section-number">1</span> Welcome to the tlverse</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> The Roadmap for Targeted Learning</a></li>
<li><a class="" href="data.html"><span class="header-section-number">3</span> The WASH Benefits Example Dataset</a></li>
<li><a class="active" href="origami.html"><span class="header-section-number">4</span> Cross-validation</a></li>
<li><a class="" href="sl3.html"><span class="header-section-number">5</span> Super (Machine) Learning</a></li>
<li><a class="" href="tmle3.html"><span class="header-section-number">6</span> The TMLE Framework</a></li>
<li><a class="" href="r6.html"><span class="header-section-number">7</span> A Primer on the R6 Class System</a></li>
<li><a class="" href="solutions.html"><span class="header-section-number">8</span> Exercise Solutions</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/tlverse/tmlcimx2021-workshop">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="origami" class="section level1">
<h1>
<span class="header-section-number">4</span> Cross-validation<a class="anchor" aria-label="anchor" href="#origami"><i class="fas fa-link"></i></a>
</h1>
<p><em>Ivana Malenica</em></p>
<p>Based on the <a href="https://github.com/tlverse/origami"><code>origami</code> <code>R</code> package</a>
by <em>Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips</em>.</p>
<p>Updated: 2021-08-16</p>
<div id="learning-objectives-1" class="section level2 unnumbered">
<h2>Learning Objectives<a class="anchor" aria-label="anchor" href="#learning-objectives-1"><i class="fas fa-link"></i></a>
</h2>
<p>By the end of this chapter you will be able to:</p>
<ol start="2" style="list-style-type: decimal">
<li>Reliably assess the performance of a machine learning algorithm, or compare
the performance of several algorithms by applying cross-validation schemes
using the <code>origami</code> <code>R</code> package.</li>
</ol>
</div>
<div id="introduction-1" class="section level2">
<h2>
<span class="header-section-number">4.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-1"><i class="fas fa-link"></i></a>
</h2>
<p>In this chapter, we start elaborating on the estimation step outlined in the
<a href="intro.html#intro">introductory chapter</a>, which discussed the <a href="intro.html#roadmap"><em>Roadmap for Targeted
Learning</em></a>. In order to generate an initial estimate of our target
parameter — which is the focus of the following <a href="sl3.html#sl3">chapter on Super
Learning</a>, we first need to translate, and incorporate, our knowledge
about the data generating process into the estimation procedure, and decide how
to evaluate our estimation performance.</p>
<p>The performance, or error, of any algorithm used in the estimation procedure
directly relates to its generalizability on the independent data. The proper
assessment of the performance of proposed algorithms is extremely important; it
guides the choice of the final learning method, and it gives us a quantitative
assessment of how good the chosen algorithm is doing. In order to assess the
performance of an algorithm, we introduce the concept of a <strong>loss</strong> function,
which helps us define the <strong>risk</strong>, also referred to as the <strong>expected
prediction error</strong>.</p>
<p><strong><em>Constructing a library that is consistent with the data-generating distribution</em></strong></p>
<p>Our goal, as further specified in the next chapter, will be to estimate the true
risk of the proposed statistical learning method. Our goal(s) consist of:</p>
<ol style="list-style-type: decimal">
<li>Estimating the performance of different algorithms in order to choose the
best one.</li>
<li>Having chosen a winner, estimate the true risk of the proposed
statistical learning method.</li>
</ol>
<p>In the following, we propose a method to do so using the observed data and
<strong>cross-validation</strong> procedure using the <code>origami</code> package <span class="citation">(Coyle and Hejazi <a href="references.html#ref-coyle2018origami" role="doc-biblioref">2018</a>)</span>.</p>
</div>
<div id="background" class="section level2">
<h2>
<span class="header-section-number">4.2</span> Background<a class="anchor" aria-label="anchor" href="#background"><i class="fas fa-link"></i></a>
</h2>
<p>Ideally, in a data-rich scenario, we would split our dataset into three parts:</p>
<ol style="list-style-type: decimal">
<li>training set,</li>
<li>validation set,</li>
<li>test set.</li>
</ol>
<p>The training set is used to fit algorithm(s) of interest; we evaluate the
performance of the fit(s) on a validation set, which can be used to estimate
prediction error (e.g., for tuning and model selection). The final error of the
chosen algorithm(s) is obtained by using the test set, which is kept separately,
and doesn’t see the data before the final evaluation. One might wonder, with
training data readily available, why not use the training error to evaluate the
proposed algorithm’s performance? Unfortunately, the training error is not a
good estimate of the true risk; it consistently decreases with model complexity,
resulting in a possible overfit to the training data and low generalizability.</p>
<p>Since data are often scarce, separating it into training, validation and test
set is usually not possible. In the absence of a large data set and a designated
test set, we must resort to methods that estimate the true risk by efficient
sample re-use. Re-sampling methods, in great generality, involve repeatedly
sampling from the training set and fitting proposed algorithms on the new
samples. While often computationally intensive, re-sampling methods are
particularly useful for model selection and estimation of the true risk. In
addition, they might provide more insight on variability and robustness of the
algorithm fit then fitting an algorithm only once on all the training data.</p>
<div id="what-is-cross-validation" class="section level3">
<h3>
<span class="header-section-number">4.2.1</span> What is cross-validation?<a class="anchor" aria-label="anchor" href="#what-is-cross-validation"><i class="fas fa-link"></i></a>
</h3>
<p>In this chapter, we focus on <strong>cross-validation</strong> — an essential tool for
evaluating how any given algorithm extends from a sample to the target
population from which the sample is derived. It has seen widespread application
in all facets of statistics, perhaps most notably statistical machine learning.
The cross-validation procedure can be used for model selection, as well as for
estimation of the true risk associated with any statistical learning method in
order to evaluate its performance. It particular, cross-validation directly
estimates the true risk when the estimate is applied to an independent sample
from the joint distribution of the predictors and outcome. When used for model
selection, cross-validation has powerful optimality properties. The asymptotic
optimality results state that the cross-validated selector performs (in terms of
risk) asymptotically as well as an optimal oracle selector based on the true,
unknown data generating distribution. For further details on the theoretical
results, we suggest <span class="citation">van der Laan and Dudoit (<a href="references.html#ref-vdl2003unified" role="doc-biblioref">2003</a>)</span>, <span class="citation">van der Laan, Dudoit, and Keles (<a href="references.html#ref-vdl2004asymptotic" role="doc-biblioref">2004</a>)</span>, <span class="citation">Dudoit and van der Laan (<a href="references.html#ref-dudoit2005asymptotics" role="doc-biblioref">2005</a>)</span> and
<span class="citation">Van der Vaart, Dudoit, and Laan (<a href="references.html#ref-vaart2006oracle" role="doc-biblioref">2006</a>)</span>.</p>
<p>In great generality, cross-validation works by partitioning a sample into
complementary subsets, applying a particular algorithm(s) on a subset (the
training set), and evaluating the method of choice on the complementary subset
(the validation/test set). This procedure is repeated across multiple partitions
of the data. A variety of different partitioning schemes exist, depending on the
problem of interest, data size, prevalence of the outcome, and dependence
structure. The <code>origami</code> package provides a suite of tools that generalize the
application of cross-validation to arbitrary data analytic procedures. In the
the following, we describe different types of cross-validation schemes readily
available in <code>origami</code>, introduce the general structure of the <code>origami</code>
package, and show their use in applied settings.</p>
<hr>
</div>
</div>
<div id="roadmap-how-does-it-all-fit-together" class="section level2">
<h2>
<span class="header-section-number">4.3</span> Roadmap: How does it all fit together?<a class="anchor" aria-label="anchor" href="#roadmap-how-does-it-all-fit-together"><i class="fas fa-link"></i></a>
</h2>
<p>Similarly to how we defined the <a href="intro.html#roadmap"><em>Roadmap for Targeted Learning</em></a>, we
can define the <strong>Estimation Roadmap</strong> to guide the estimation process. In
particular, we have developed a unified loss-based cross-validation methodology
for estimator construction, selection, and performance assessment in a series of
articles (e.g., see <span class="citation">van der Laan and Dudoit (<a href="references.html#ref-vdl2003unified" role="doc-biblioref">2003</a>)</span>, <span class="citation">van der Laan, Dudoit, and Keles (<a href="references.html#ref-vdl2004asymptotic" role="doc-biblioref">2004</a>)</span>, <span class="citation">Dudoit and van der Laan (<a href="references.html#ref-dudoit2005asymptotics" role="doc-biblioref">2005</a>)</span>,
<span class="citation">Van der Vaart, Dudoit, and Laan (<a href="references.html#ref-vaart2006oracle" role="doc-biblioref">2006</a>)</span>, and <span class="citation">van der Laan, Polley, and Hubbard (<a href="references.html#ref-vdl2007super" role="doc-biblioref">2007</a>)</span>) that follow three main steps:</p>
<ol style="list-style-type: decimal">
<li><p><strong>The loss funtion</strong>:
Define the target parameter as the minimizer of the expected loss (risk) for a
full data loss function chosen to represent the desired performance measure.
Map the full data loss function into an observed data loss function, having the
same expected value and leading to an efficient estimator of risk.</p></li>
<li><p><strong>The algorithms</strong>:
Construct a finite collection of candidate estimators for the parameter of
interest.</p></li>
<li><p><strong>The cross-validation scheme</strong>:
Apply appropriate cross-validation to select an optimal estimator among the
candidates, and assess the overall performance of the resulting estimator.</p></li>
</ol>
<p>Step 1 of the Estimation Roadmap allows us to unify a broad range of problems
that are traditionally treated separately in the statistical literature,
including density estimation, prediction of polychotomous and continuous
outcomes. For example, if we are interested in estimating the full joint
conditional density, we could use the negative log-likelihood loss. If instead
we are interested in the conditional mean with continuous outcome, one could use
the squared error loss; had the outcome been binary, one could resort to the
indicator (0-1) loss. The unified loss-based framework also reconciles censored
and full data estimation methods, by generalizing any loss based learning for
full data into loss based learning for general censored data.</p>
</div>
<div id="example-cross-validation-and-prediction" class="section level2">
<h2>
<span class="header-section-number">4.4</span> Example: cross-validation and prediction<a class="anchor" aria-label="anchor" href="#example-cross-validation-and-prediction"><i class="fas fa-link"></i></a>
</h2>
<p>Now that we introduced the Estimation Roadmap, we can define our objective with
more mathematical notation, using prediction as an example. Let the observed
data be defined as <span class="math inline">\(X = (W,Y)\)</span>, where a unit specific data can be written as
<span class="math inline">\(X_i = (W_i,Y_i)\)</span>, for <span class="math inline">\(i = 1, \ldots, n\)</span>. For each of the <span class="math inline">\(n\)</span> samples, we
denote <span class="math inline">\(Y_i\)</span> as the outcome of interest (polychotomous or continuous), and <span class="math inline">\(W_i\)</span>
as a <span class="math inline">\(p\)</span>-dimensional set of covariates. Let <span class="math inline">\(\psi_0(W)\)</span> denote the target
parameter of interest we want to estimate; for this example, we are interested
in estimating the conditional expectation of the outcome given the covariates,
<span class="math inline">\(\psi_0(W) = E(Y \mid W)\)</span>. Following the Estimation Roadmap, we chose the
appropriate loss function, <span class="math inline">\(L\)</span>, such that <span class="math inline">\(\psi_0(W) = \text{argmin}_{\psi} E[L(X,\psi(W))]\)</span>. But how do we know how each <span class="math inline">\(\psi\)</span> is doing? In order to pick
the optimal estimator among the candidates, and assess the overall performance
of the resulting estimator, we use cross-validation — dividing the available
data into the training set and validation set. Observations in the training set
are used to fit (or train) the estimator, while the validation set is used to
assess the risk of (or validate) it.</p>
<p>To derive a general representation for cross-validation, we define a <strong>split
vector</strong>, <span class="math inline">\(B_n = (B_n(i): i = 1, \ldots, n) \in \{0,1\}^n\)</span>. Note that split
vector is independent of the empirical distribution, <span class="math inline">\(P_n\)</span>. A realization of
<span class="math inline">\(B_n\)</span> defines a random split of the data into a training and validation set such
that if</p>
<p><span class="math display">\[B_n(i) = 0, \ \ \text{i sample is in the training set}\]</span>
<span class="math display">\[B_n(i) = 1, \ \ \text{i sample is in the validation set.}\]</span>
We can further define <span class="math inline">\(P_{n,B_n}^0\)</span> and <span class="math inline">\(P_{n,B_n}^1\)</span> as the empirical
distributions of the training and validation sets, respectively. Then <span class="math inline">\(n_0 = \sum_i (1-B_n(i))\)</span> and <span class="math inline">\(n_1 = \sum_i B_n(i)\)</span> denote the number of samples in each
set. The particular distribution of the split vector <span class="math inline">\(B_n\)</span> defines the type of
cross-validation scheme, tailored to the problem and data set in hand.</p>
</div>
<div id="cross-validation-schemes-in-origami" class="section level2">
<h2>
<span class="header-section-number">4.5</span> Cross-validation schemes in <code>origami</code><a class="anchor" aria-label="anchor" href="#cross-validation-schemes-in-origami"><i class="fas fa-link"></i></a>
</h2>
<p>As we specified earlier, the particular distribution of the split vector <span class="math inline">\(B_n\)</span>
defines the type of the cross-validation method. In the following, we describe
different types of cross-validation schemes available in <code>origami</code> package, and
show their use in the sequel.</p>
<div id="wash-benefits-study-example" class="section level3 unnumbered">
<h3>WASH Benefits study example<a class="anchor" aria-label="anchor" href="#wash-benefits-study-example"><i class="fas fa-link"></i></a>
</h3>
<p>In order to illustrate different cross-validation schemes, we will be using the
WASH data. Detailed information on the WASH Benefits example dataset can be
found in <span id="data">Chapter 3</span>. In particular, we are interested in predicting
weight-for-height z-score <code>whz</code> using the available covariate data. For this
illustration, we will start by treating the data as independent and identically
distributed (i.i.d.) random draws. To see what each cross-validation scheme is
doing, we will subset the data to only <span class="math inline">\(n=30\)</span>. Note that each row represents an
i.i.d. sample, indexed by the row number.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com">data.table</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/origami">origami</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://yihui.org/knitr/">knitr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://haozhu233.github.io/kableExtra/">kableExtra</a></span><span class="op">)</span>

<span class="co"># load data set and take a peek</span>
<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span>
    <span class="st">"https://raw.githubusercontent.com/tlverse/tlverse-data/master/"</span>,
    <span class="st">"wash-benefits/washb_data.csv"</span>
  <span class="op">)</span>,
  stringsAsFactors <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whz
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
tr
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fracode
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aged
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sex
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momage
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momedu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momheight
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hfiacat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Nlt18
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Ncomp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
watmin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
elec
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
floor
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
walls
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
roof
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_wardrobe
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_table
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chair
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_khat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chouki
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_tv
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_refrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_bike
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_moto
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_sewmach
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_mobile
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
146.40
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.16
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
148.75
</td>
<td style="text-align:left;">
Moderately Food Insecure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.05
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
264
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
152.15
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.26
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
252
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
140.25
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
336
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
150.95
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.51
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
304
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
154.20
</td>
<td style="text-align:left;">
Severely Food Insecure
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table></div>
</div>
<p>Above is a look at the first 30 of the data.</p>
</div>
<div id="cross-validation-for-i.i.d.-data" class="section level3">
<h3>
<span class="header-section-number">4.5.1</span> Cross-validation for i.i.d. data<a class="anchor" aria-label="anchor" href="#cross-validation-for-i.i.d.-data"><i class="fas fa-link"></i></a>
</h3>
<div id="re-substitution" class="section level4">
<h4>
<span class="header-section-number">4.5.1.1</span> Re-substitution<a class="anchor" aria-label="anchor" href="#re-substitution"><i class="fas fa-link"></i></a>
</h4>
<p>The re-substitution method is the simplest strategy for estimating the risk
associated with fitting a proposed algorithm on a set of observations. Here, all
observed data is used for both training and validation set.</p>
<p>We illustrate the usage of the re-substitution method with <code>origami</code> package
below; we will use the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_resubstitution(n)</a></code>. In order to setup
<code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_resubstitution(n)</a></code>, we just need the total number of samples we want to
allocate to training and validation sets; remember that each row of data is a
unique i.i.d. sample. Notice the structure of the <code>origami</code> output:</p>
<ol style="list-style-type: decimal">
<li>
<strong>v:</strong> the cross-validation fold</li>
<li>
<strong>training_set:</strong> the indexes of the samples in the training set</li>
<li>
<strong>validation_set:</strong> the indexes of the samples in the training set.</li>
</ol>
<p>This structure of the <code>origami</code> output (aka, fold(s)) will persist for each of the
cross-validation schemes we present in this chapter. Below, we show the fold
generated by the re-substitution method:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_resubstitution</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [[1]]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="holdout-method" class="section level4">
<h4>
<span class="header-section-number">4.5.1.2</span> Holdout method<a class="anchor" aria-label="anchor" href="#holdout-method"><i class="fas fa-link"></i></a>
</h4>
<p>The holdout method, or the validation set approach, consists of randomly
dividing the available data into the training set and validation set (holdout
set). The model is then fitted on the training set, and further evaluated on
the observations in the validation set. Typically, the data is split into
<span class="math inline">\(60/40\)</span>, <span class="math inline">\(70/30\)</span>, <span class="math inline">\(80/20\)</span> or <span class="math inline">\(90/10\)</span> splits.</p>
<p>The holdout method is intuitive, conceptually easy, and computationally not too
demanding. However, if we repeat the process of randomly splitting the data into
the training and validation set, we might get a very different cross-validated
emprical risk. In particular, the emprical mean of the loss over the validation
sets might be highly variable, depending on which samples were included in the
training/validation split. Overall, the cross-validated emprical risk for the
holdout method is more variabiable, since in includes variability of the random
split as well - which is not what we want. For classification problems, there is a
possibility of an uneven distribution of different classes in the training and validation
set unless data is stratified. Finally, note that we are not using all of the
data to train and evaluate the performance of the proposed algorithm, which might
result in bias.</p>
</div>
<div id="leave-one-out" class="section level4">
<h4>
<span class="header-section-number">4.5.1.3</span> Leave-one-out<a class="anchor" aria-label="anchor" href="#leave-one-out"><i class="fas fa-link"></i></a>
</h4>
<p>The leave-one-out cross-validation scheme is closely related to the holdout
method. In particular, it also involves splitting the data into the training and
validation set; however, instead of partitioning the observed data into sets of
similar size, a single observation is used as a validation set. With that,
majority of the units are employed for training (fitting) the proposed
algorithm. Since only one unit (for example <span class="math inline">\(x_1 = (w_1, y_1)\)</span>) is not used in
the fitting process, leave-one-out cross-validation results in a possibly less
biased estimate of the true risk; typically, leave-one-out approach will not
overestimate the risk as much as the holdout method. On the other hand, since
the estimate of risk is based on a single sample, it is typically a highly
variable estimate.</p>
<p>We can repeat the process of spiting the data into training and validation set
until all samples are part of the validation set at some point. For example,
next iteration of the cross-validation might have <span class="math inline">\(x_2 = (w_2,y_2)\)</span> as the
validation set and all the rest of <span class="math inline">\(n-1\)</span> samples as the training set. Repeating
this approach <span class="math inline">\(n\)</span> times results in, for example, <span class="math inline">\(n\)</span> squared errors <span class="math inline">\(MSE_1, MSE_2, \ldots, MSE_n\)</span>. The estimate of the true risk is the average over the
<span class="math inline">\(n\)</span> squared errors. While the leave-one-out cross-validation results in a less
biased (albeit, more variable) estimate of risk than the holdout method, it
could be expensive to implement if <span class="math inline">\(n\)</span> is large.</p>
<p>We illustrate the usage of the leave-one-out cross-validation with <code>origami</code>
package below; we will use the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_loo(n)</a></code>. In order to setup
<code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_loo(n)</a></code>, similarly to the re-substitution method, we just need the total
number of samples we want to cross-validate. We show the first two folds
generated by the leave-one-out cross-validation below.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_loo</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span><span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26</span>
<span class="co">#&gt; [26] 27 28 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26</span>
<span class="co">#&gt; [26] 27 28 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="v-fold" class="section level4">
<h4>
<span class="header-section-number">4.5.1.4</span> V-fold<a class="anchor" aria-label="anchor" href="#v-fold"><i class="fas fa-link"></i></a>
</h4>
<p>An alternative to leave-one-out is V-fold cross-validation. This
cross-validation scheme randomly divides the data into <span class="math inline">\(v\)</span> sets (folds) of equal
size; for each fold, the number of samples in the validation set are the same.
For V-fold cross-validation, one of the folds is treated as a validation set,
whereas the proposed algorithm is fit on the remaining <span class="math inline">\(v-1\)</span> folds in the
training set. The loss, for example MSE, is computed on the samples in the
validation set. With the proposed algorithm trained and its performance
evaluated on the first fold, we repeat this process <span class="math inline">\(v\)</span> times; each time, a
different group of samples is treated as a validation set. Note that with V-fold
cross-validation we effectively use all of the data to train and evaluate the
proposed algorithm without overfitting to the training data. In the end, the
V-fold cross-validation results in <span class="math inline">\(v\)</span> estimates of validation error. The final
V-fold CV estimate is computed as an average over all the validation losses.</p>
<p>For a dataset with <span class="math inline">\(n\)</span> samples, V-fold cross-validation with <span class="math inline">\(v=n\)</span> is just
leave-one-out; similarly, if we set <span class="math inline">\(n=1\)</span>, we can get the holdout method’s
estimate of algorithm’s performance. Despite the obvious computational
advantages, V-fold cross-validation often gives more accurate estimates of the
true risk. The reason for this comes from the bias-variance trade-off that comes
from employing both methods; while leave-one-out might be less biased, it has
higher variance. This difference becomes more obvious as <span class="math inline">\(v&lt;&lt;n\)</span> (but not too
small, as then we increase bias). With V-fold cross-validation, we end up
averaging output from <span class="math inline">\(v\)</span> fits that are typically less correlated than the
outputs from leave-one-out fits. Since the mean of many highly correlated
quantities has higher variance, leave-one-out estimate of the risk will
have higher variance than the estimate based on V-fold cross-validation.</p>
<p>Let’s see V-fold cross-validation with <code>origami</code> in action! In the next chapter
we will study the Super Learner — an actual algorithm that we fit and evaluate
its performance. The Super Learner relies on V-fold cross-validation as default
cross-validation scheme. In order to set up V-fold CV, we need to call function
<code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold(n, V)</a></code>. Arguments for <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold(n, V)</a></code> require the total number
of samples to be cross-validated, and the number of folds we want to get.</p>
<p>At <span class="math inline">\(V=2\)</span>, we get 2 folds with <span class="math inline">\(n/2\)</span> number of samples in both training and
validation set.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>, V <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  2  3  4  6  7  8 11 12 14 15 19 22 23 24 28</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  1  5  9 10 13 16 17 18 20 21 25 26 27 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  5  9 10 13 16 17 18 20 21 25 26 27 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  2  3  4  6  7  8 11 12 14 15 19 22 23 24 28</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="monte-carlo" class="section level4">
<h4>
<span class="header-section-number">4.5.1.5</span> Monte Carlo<a class="anchor" aria-label="anchor" href="#monte-carlo"><i class="fas fa-link"></i></a>
</h4>
<p>With Monte Carlo cross-validation, we randomly select some fraction of the data
(without replacement) to form the training set; we assign the rest of the
samples to the validation set. With that, the data is repeatedly and randomly
divided into two sets, a training set of <span class="math inline">\(n_0 = n \cdot (1-p)\)</span> observations and
a validation set of <span class="math inline">\(n_1 = n \cdot p\)</span> observations. This process is then
repeated multiple times, generating (at random) new training and validation
partitions each time.</p>
<p>Since the partitions are independent across folds, the same sample can appear in
the validation set multiple times — note that this is a stark difference
between Monte Carlo and V-fold cross-validation. For a given <span class="math inline">\(p\)</span>, Monte Carlo
cross-validation would be optimal if done infinite times, but this is not
computationally feasible. With Monte Carlo cross-validation, one is able to
explore many more available partitions than with V-fold cross-validation —
resulting in a possibly less variable estimate of the risk, at a cost of an
increase in bias. By having many overlapping splits, we often also need more
splits (and thus more computational time) to achieve V-fold performance with
only <span class="math inline">\(V\)</span> splits.</p>
<p>We illustrate the usage of the Monte Carlo cross-validation with <code>origami</code>
package below using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_montecarlo(n, V, pvalidation)</a></code>. In order
to setup <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_montecarlo(n, V, pvalidation)</a></code>, we need</p>
<ol style="list-style-type: decimal">
<li>the total number of samples we want to cross-validate (<code>n</code>);</li>
<li>the number of folds (<code>V</code>);</li>
<li>the proportion of observations to be placed in the validation set
(<code>pvalidation</code>).</li>
</ol>
<p>At <code>V=2</code> and <code>pvalidation=0.2</code>, we obtain 2 folds with approximately <span class="math inline">\(6\)</span> samples
in validation set per fold.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_montecarlo</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>, V <span class="op">=</span> <span class="fl">2</span>, pvalidation <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1] 19 27 16 29 23 12  1  3 18 11  5  7  8  6  9 22 10 25 20 28 15  2 24 26</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt; [1]  4 13 14 17 21 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1] 19 15 28 25 29 11 20 17 14  4  9 12 30  8 27 18 16 10 13  6 24  3 26  1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt; [1]  2  5  7 21 22 23</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="bootstrap" class="section level4">
<h4>
<span class="header-section-number">4.5.1.6</span> Bootstrap<a class="anchor" aria-label="anchor" href="#bootstrap"><i class="fas fa-link"></i></a>
</h4>
<p>The bootstrap cross-validation also consists of randomly selecting samples, with
replacement, for the training set. The rest of the samples not picked for the
training set are allocated to the validation set. This process is then repeated
multiple times, generating (at random) new training and validation partitions
each time. In contract to the Monte Carlo cross-validation, the total number of
samples in a training and validation size across folds is not constant. We also
sample with replacement, hence the same samples can be in multiple training
sets. The proportion of observations in the validation sets is a random
variable, with expectation <span class="math inline">\(\sim 0.368\)</span>.</p>
<p>We illustrate the usage of the bootstrap cross-validation with <code>origami</code> package
below using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_bootstrap(n, V)</a></code>. In order to setup
<code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_bootstrap(n, V)</a></code>, we need</p>
<ol style="list-style-type: decimal">
<li>the total number of samples we want to cross-validate (<code>n</code>); and</li>
<li>the number of folds (<code>V</code>).</li>
</ol>
<p>At <span class="math inline">\(V=2\)</span>, we obtain <span class="math inline">\(2\)</span> folds with different number of samples in the validation
set across folds.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_bootstrap</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>, V <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  2  5 30  1 29 16 10 11  8 25 28  2 11  2 16 28 15 28  1 27  9 19 20 30 18</span>
<span class="co">#&gt; [26] 11 13  2 18 12</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  3  4  6  7 14 17 21 22 23 24 26</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1] 12 16 10 29 22 15 27  9 27 16 12 28 10 28 26  1 14  6 23 14 21 16  5 20  8</span>
<span class="co">#&gt; [26] 23 25  8 27  5</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  2  3  4  7 11 13 17 18 19 24 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
</div>
<div id="cross-validation-for-dependent-data" class="section level3">
<h3>
<span class="header-section-number">4.5.2</span> Cross-validation for dependent data<a class="anchor" aria-label="anchor" href="#cross-validation-for-dependent-data"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>origami</code> package also supports numerous cross-validation schemes for
time-series data, for both single and multiple time-series with arbitrary time
and network dependence.</p>
</div>
<div id="airpassenger-example" class="section level3 unnumbered">
<h3>AirPassenger Example<a class="anchor" aria-label="anchor" href="#airpassenger-example"><i class="fas fa-link"></i></a>
</h3>
<p>In order to illustrate different cross-validation schemes for time-series, we
will be using the AirPassenger data; this is a widely used, freely available
dataset. The AirPassenger dataset in <code>R</code> provides monthly totals of
international airline passengers from 1949 to 1960. This dataset is already of a
time series class therefore no further class or date manipulation is required.</p>
<p><strong><em>Constructing a library that is consistent with the data-generating distribution</em></strong>
<strong>Goal:</strong> we want to forecast the number of airline passengers at some future
time (i.e., horizon) <span class="math inline">\(h\)</span> using the historical data from 1949 to 1960.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/sinhrks/ggfortify">ggfortify</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">AirPassengers</span><span class="op">)</span>
<span class="va">AP</span> <span class="op">&lt;-</span> <span class="va">AirPassengers</span>

<span class="fu">autoplot</span><span class="op">(</span><span class="va">AP</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>
    x <span class="op">=</span> <span class="st">"Date"</span>,
    y <span class="op">=</span> <span class="st">"Passenger numbers (1000's)"</span>,
    title <span class="op">=</span> <span class="st">"Air Passengers from 1949 to 1961"</span>
  <span class="op">)</span>

<span class="va">t</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">AP</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="05-origami_files/figure-html/plot_airpass-1.png" width="80%" style="display: block; margin: auto;"></div>
<div id="rolling-origin" class="section level4">
<h4>
<span class="header-section-number">4.5.2.1</span> Rolling origin<a class="anchor" aria-label="anchor" href="#rolling-origin"><i class="fas fa-link"></i></a>
</h4>
<p>Rolling origin cross-validation scheme lends itself to “online” algorithms,
where large streams of data have to be fit continually, and the final fit is
constantly updated with more data acquired. In general, the rolling origin
scheme defines an initial training set, and with each iteration the size of the
training set grows by <span class="math inline">\(m\)</span> observations until we reach time <span class="math inline">\(t\)</span> for a particular
fold. The time points included in the training set are always behind the
validation set time points; in addition, there might be a gap between training
and validation times of size <span class="math inline">\(h\)</span>.</p>
<p>To further illustrate rolling origin cross-validation, we show below an example
with 3 folds. Here, the first window size is 15 time points, on which we first
train the proposed algorithm. We then evaluate its performance on 10 time
points, with a gap of size 5 between the training and validation time points.
For the following fold, we train the algorithm on a longer stream of data, 25
time points, including the original 15 we started with. We then evaluate its
performance on 10 time points in the future.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-1"></span>
<img src="img/png/rolling_origin.png" alt="Rolling origin CV" width="80%"><p class="caption">
FIGURE 4.1: Rolling origin CV
</p>
</div>
<p>We illustrate the usage of the rolling origin cross-validation with <code>origami</code>
package below using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_origin(n, first_window, validation_size, gap, batch)</a></code>. In order to setup <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_origin(n, first_window, validation_size, gap, batch)</a></code>, we need</p>
<ol style="list-style-type: decimal">
<li>the total number of time points we want to cross-validate (<code>n</code>);</li>
<li>the size of the first training set (<code>first_window</code>);</li>
<li>the size of the validation set (<code>validation_size</code>);</li>
<li>the gap between training and validation set (<code>gap</code>);</li>
<li>the size of the update on the training set per each iteration of CV (<code>batch</code>).</li>
</ol>
<p>Our time-series has <span class="math inline">\(t=144\)</span> time points. Setting the <code>first_window</code> to <span class="math inline">\(50\)</span>,
<code>validation_size</code> to 10, <code>gap</code> to 5 and <code>batch</code> to 20, we get 4 time-series
folds; we show the first two below.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_origin</a></span><span class="op">(</span>
  <span class="va">t</span>,
  first_window <span class="op">=</span> <span class="fl">50</span>, validation_size <span class="op">=</span> <span class="fl">10</span>, gap <span class="op">=</span> <span class="fl">5</span>, batch <span class="op">=</span> <span class="fl">20</span>
<span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 56 57 58 59 60 61 62 63 64 65</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50</span>
<span class="co">#&gt; [51] 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 76 77 78 79 80 81 82 83 84 85</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="rolling-window" class="section level4">
<h4>
<span class="header-section-number">4.5.2.2</span> Rolling window<a class="anchor" aria-label="anchor" href="#rolling-window"><i class="fas fa-link"></i></a>
</h4>
<p>Instead of adding more time points to the training set per each iteration, the
rolling window cross-validation scheme “rolls” the training sample forward by
<span class="math inline">\(m\)</span> time units. The rolling window scheme might be considered in parametric
settings when one wishes to guard against moment or parameter drift that is
difficult to model explicitly; it is also more efficient for computationally
demanding settings such as streaming data, in which large amounts of training
data cannot be stored. In contrast to rolling origin CV, the training sample for
each iteration of the rolling window scheme is always the same.</p>
<p>To illustrate the rolling window cross-validation with 3 time-series folds
below. The first window size is 15 time points, on which we first train the
proposed algorithm. As in the previous illustration, we evaluate its performance
on 10 time points, with a gap of size 5 between the training and validation time
points. However, for the next fold, we train the algorithm on time points
further away from the origin (here, 10 time points). Note that the size of the
training set in the new fold is the same as in the first fold (15 time points).
This setup keeps the training sets comparable over time (and fold) as compared
to the rolling origin CV. We then evaluate the performance of the proposed
algorithm on 10 time points in the future.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-2"></span>
<img src="img/png/rolling_window.png" alt="Rolling window CV" width="80%"><p class="caption">
FIGURE 4.2: Rolling window CV
</p>
</div>
<p>We illustrate the usage of the rolling window cross-validation with <code>origami</code>
package below using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_window(n, window_size, validation_size, gap, batch)</a></code>. In order to setup <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_window(n, window_size, validation_size, gap, batch)</a></code>, we need:</p>
<ol style="list-style-type: decimal">
<li>the total number of time points we want to cross-validate (<code>n</code>);</li>
<li>the size of the training sets (<code>window_size</code>);</li>
<li>the size of the validation set (<code>validation_size</code>);</li>
<li>the gap between training and validation set (<code>gap</code>); and</li>
<li>the size of the update on the training set per each iteration of CV (<code>batch</code>).</li>
</ol>
<p>Setting the <code>window_size</code> to <span class="math inline">\(50\)</span>, <code>validation_size</code> to 10, <code>gap</code> to 5 and
<code>batch</code> to 20, we also get 4 time-series folds; we show the first two below.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_window</a></span><span class="op">(</span>
  <span class="va">t</span>,
  window_size <span class="op">=</span> <span class="fl">50</span>, validation_size <span class="op">=</span> <span class="fl">10</span>, gap <span class="op">=</span> <span class="fl">5</span>, batch <span class="op">=</span> <span class="fl">20</span>
<span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 56 57 58 59 60 61 62 63 64 65</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1] 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45</span>
<span class="co">#&gt; [26] 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 76 77 78 79 80 81 82 83 84 85</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="rolling-origin-with-v-fold" class="section level4">
<h4>
<span class="header-section-number">4.5.2.3</span> Rolling origin with V-fold<a class="anchor" aria-label="anchor" href="#rolling-origin-with-v-fold"><i class="fas fa-link"></i></a>
</h4>
<p>A variant of rolling origin scheme which accounts for sample dependence is the
rolling-origin-<span class="math inline">\(V\)</span>-fold cross-validation. In contrast to the canonical rolling
origin CV, samples in the training and validation set are not the same, as the
variant encompasses <span class="math inline">\(V\)</span>-fold CV in addition to the time-series setup. The
predictions are evaluated on the future times of time-series units not seen
during the training step, allowing for dependence in both samples and time. One
can use the rolling-origin-<span class="math inline">\(v\)</span>-fold cross-validation with <code>origami</code> package
using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold_rolling_origin_pooled(n, t, id, time, V, first_window, validation_size, gap, batch)</a></code>. In the figure below, we show <span class="math inline">\(V=2\)</span>
<span class="math inline">\(V\)</span>-folds, and 2 time-series CV folds.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-3"></span>
<img src="img/png/rolling_origin_v_fold.png" alt="Rolling origin V-fold CV" width="80%"><p class="caption">
FIGURE 4.3: Rolling origin V-fold CV
</p>
</div>
</div>
<div id="rolling-window-with-v-fold" class="section level4">
<h4>
<span class="header-section-number">4.5.2.4</span> Rolling window with V-fold<a class="anchor" aria-label="anchor" href="#rolling-window-with-v-fold"><i class="fas fa-link"></i></a>
</h4>
<p>Analogous to the previous section, we can extend rolling window CV to support
multiple time-series with arbitrary sample dependence. One can use the
rolling-window-<span class="math inline">\(V\)</span>-fold cross-validation with <code>origami</code> package using the
function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold_rolling_window_pooled(n, t, id, time, V, window_size, validation_size, gap, batch)</a></code>. In the figure below, we show <span class="math inline">\(V=2\)</span> <span class="math inline">\(V\)</span>-folds, and
2 time-series CV folds.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-4"></span>
<img src="img/png/rolling_window_v_fold.png" alt="Rolling window V-fold CV" width="80%"><p class="caption">
FIGURE 4.4: Rolling window V-fold CV
</p>
</div>
</div>
</div>
</div>
<div id="general-workflow-of-origami" class="section level2">
<h2>
<span class="header-section-number">4.6</span> General workflow of <code>origami</code><a class="anchor" aria-label="anchor" href="#general-workflow-of-origami"><i class="fas fa-link"></i></a>
</h2>
<p>Before we dive into more details, let’s take a moment to review some of the
basic functionality in <code>origami</code> R package. The main function in the <code>origami</code>
is <code>cross_validate</code>. To start off, the user must define the fold structure and a
function that operates on each fold. Once these are passed to <code>cross_validate</code>,
<code>cross_validate</code> will apply the same specified function to each fold, and
combine the fold-specific results in a meaningful way. We will see this in
action in later sections; for now, we provide specific details on each each step
of this process below.</p>
<div id="define-folds" class="section level3 unnumbered">
<h3>(1) Define folds<a class="anchor" aria-label="anchor" href="#define-folds"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>folds</code> object passed to <code>cross_validate</code> is a list of folds; such lists can
be generated using the <code>make_folds</code> function. Each fold consists of a list with
a <code>training</code> index vector, a <code>validation</code> index vector, and a <code>fold_index</code> (its
order in the list of folds). This function supports a variety of
cross-validation schemes we describe in the following section. The <code>make_folds</code>
can balance across levels of a variable (<code>strata_ids</code>), and it can also keep
all observations from the same independent unit together (<code>cluster</code>).</p>
</div>
<div id="define-fold-function" class="section level3 unnumbered">
<h3>(2) Define fold function<a class="anchor" aria-label="anchor" href="#define-fold-function"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>cv_fun</code> argument to <code>cross_validate</code> is a function that will perform some
operation on each fold. The first argument to this function must be <code>fold</code>,
which will receive an individual fold object to operate on. Additional arguments
can be passed to <code>cv_fun</code> using the <code>...</code> argument to <code>cross_validate</code>. Within
this function, the convenience functions <code>training</code>, <code>validation</code> and
<code>fold_index</code> can return the various components of a fold object. If <code>training</code>
or <code>validation</code> is passed an object, it will index it in a sensible way.
For instance, if it is a vector, it will index the vector directly; if it is a
<code>data.frame</code> or <code>matrix</code>, it will index rows. This allows the user to easily
partition data into training and validation sets. The fold function must return
a named list of results containing whatever fold-specific outputs are generated.</p>
</div>
<div id="apply-cross_validate" class="section level3 unnumbered">
<h3>(3) Apply <code>cross_validate</code><a class="anchor" aria-label="anchor" href="#apply-cross_validate"><i class="fas fa-link"></i></a>
</h3>
<p>After defining folds, <code>cross_validate</code> can be used to map the <code>cv_fun</code> across
the <code>folds</code> using <code>future_lapply</code>. This means that it can be easily parallelized
by specifying a parallelization scheme (i.e., a <code>plan</code> from the <a href="https://Cran.R-project.org/package=future">future
parallelization framework for <code>R</code></a>
<span class="citation">(Bengtsson <a href="references.html#ref-bengtsson2020unifying" role="doc-biblioref">2020</a>)</span>). The application of <code>cross_validate</code> generates a list
of results. As described above, each call to <code>cv_fun</code> itself returns a list of
results, with different elements for each type of result we care about. The main
loop generates a list of these individual lists of results (a sort of
“meta-list”). This “meta-list” is then inverted such that there is one element
per result type (this too is a list of the results for each fold). By default,
<code>combine_results</code> is used to combine these results type lists in a sensible
manner. How results are combined is determined automatically by examining the
data types of the results from the first fold. This can be modified by
specifying a list of arguments to <code>.combine_control</code>.</p>
</div>
</div>
<div id="cross-validation-in-action" class="section level2">
<h2>
<span class="header-section-number">4.7</span> Cross-validation in action<a class="anchor" aria-label="anchor" href="#cross-validation-in-action"><i class="fas fa-link"></i></a>
</h2>
<p>Let’s see <code>origami</code> in action! In the following chapter we will learn how to use
cross-validation with the Super Learner, and how we can utilize the power of
cross-validation to build optimal ensembles of algorithms, not just its use on a
single statistical learning method.</p>
<div id="cross-validation-with-linear-regression" class="section level3">
<h3>
<span class="header-section-number">4.7.1</span> Cross-validation with linear regression<a class="anchor" aria-label="anchor" href="#cross-validation-with-linear-regression"><i class="fas fa-link"></i></a>
</h3>
<p>First, we will load the relevant <code>R</code> packages, set a seed, and load the full
WASH data once again. In order to illustrate cross-validation with <code>origami</code> and
linear regression, we will focus on predicting the weight-for-height Z-score
<code>whz</code> using all of the available covariate data. As stated previously, we will
assume the data is independent and identically distributed, ignoring the cluster
structure imposed by the clinical trial design. For the sake of illustration, we
will work with a subset of data, and remove all samples with missing data from
the dataset; we will learn in the next chapter how to deal with missingness.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://stringr.tidyverse.org">stringr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org">tidyr</a></span><span class="op">)</span>

<span class="co"># load data set and take a peek</span>
<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span>
    <span class="st">"https://raw.githubusercontent.com/tlverse/tlverse-data/master/"</span>,
    <span class="st">"wash-benefits/washb_data.csv"</span>
  <span class="op">)</span>,
  stringsAsFactors <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>

<span class="co"># Remove missing data, then pick just the first 500 rows</span>
<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="va">washb_data</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/drop_na.html">drop_na</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">500</span><span class="op">)</span>

<span class="va">outcome</span> <span class="op">&lt;-</span> <span class="st">"whz"</span>
<span class="va">covars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span> <span class="op">==</span> <span class="va">outcome</span><span class="op">)</span><span class="op">]</span></code></pre></div>
<p>Here’s a look at the data:</p>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whz
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
tr
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fracode
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aged
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sex
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momage
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momedu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momheight
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hfiacat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Nlt18
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Ncomp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
watmin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
elec
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
floor
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
walls
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
roof
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_wardrobe
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_table
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chair
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_khat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chouki
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_tv
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_refrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_bike
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_moto
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_sewmach
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_mobile
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
146.40
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.16
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
148.75
</td>
<td style="text-align:left;">
Moderately Food Insecure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.05
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
264
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
152.15
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.26
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
252
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
140.25
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
336
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
150.95
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.51
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
304
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
154.20
</td>
<td style="text-align:left;">
Severely Food Insecure
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table></div>
</div>
<p>We can see the covariates used in the prediction:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">outcome</span>
<span class="co">#&gt; [1] "whz"</span>
<span class="va">covars</span>
<span class="co">#&gt;  [1] "tr"             "fracode"        "month"          "aged"          </span>
<span class="co">#&gt;  [5] "sex"            "momage"         "momedu"         "momheight"     </span>
<span class="co">#&gt;  [9] "hfiacat"        "Nlt18"          "Ncomp"          "watmin"        </span>
<span class="co">#&gt; [13] "elec"           "floor"          "walls"          "roof"          </span>
<span class="co">#&gt; [17] "asset_wardrobe" "asset_table"    "asset_chair"    "asset_khat"    </span>
<span class="co">#&gt; [21] "asset_chouki"   "asset_tv"       "asset_refrig"   "asset_bike"    </span>
<span class="co">#&gt; [25] "asset_moto"     "asset_sewmach"  "asset_mobile"</span></code></pre></div>
<p>Next, we fit a linear model on the full data, with the goal of predicting the
weight-for-height Z-score <code>whz</code> using all of the available covariate data. Let’s
try it out:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">whz</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">washb_data</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm_mod</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = whz ~ ., data = washb_data)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -2.8890 -0.6799 -0.0169  0.6595  3.1005 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                                 Estimate Std. Error t value Pr(&gt;|t|)   </span>
<span class="co">#&gt; (Intercept)                     -1.89006    1.72022   -1.10   0.2725   </span>
<span class="co">#&gt; trHandwashing                   -0.25276    0.17032   -1.48   0.1385   </span>
<span class="co">#&gt; trNutrition                     -0.09695    0.15696   -0.62   0.5371   </span>
<span class="co">#&gt; trNutrition + WSH               -0.09587    0.16528   -0.58   0.5622   </span>
<span class="co">#&gt; trSanitation                    -0.27702    0.15846   -1.75   0.0811 . </span>
<span class="co">#&gt; trWSH                           -0.02846    0.15967   -0.18   0.8586   </span>
<span class="co">#&gt; trWater                         -0.07148    0.15813   -0.45   0.6515   </span>
<span class="co">#&gt; fracodeN05160                    0.62355    0.30719    2.03   0.0430 * </span>
<span class="co">#&gt; fracodeN05265                    0.38762    0.31011    1.25   0.2120   </span>
<span class="co">#&gt; fracodeN05359                    0.10187    0.31329    0.33   0.7452   </span>
<span class="co">#&gt; fracodeN06229                    0.30933    0.29766    1.04   0.2993   </span>
<span class="co">#&gt; fracodeN06453                    0.08066    0.30006    0.27   0.7882   </span>
<span class="co">#&gt; fracodeN06458                    0.43707    0.29970    1.46   0.1454   </span>
<span class="co">#&gt; fracodeN06473                    0.45406    0.30912    1.47   0.1426   </span>
<span class="co">#&gt; fracodeN06479                    0.60994    0.31463    1.94   0.0532 . </span>
<span class="co">#&gt; fracodeN06489                    0.25923    0.31901    0.81   0.4169   </span>
<span class="co">#&gt; fracodeN06500                    0.07539    0.35794    0.21   0.8333   </span>
<span class="co">#&gt; fracodeN06502                    0.36748    0.30504    1.20   0.2290   </span>
<span class="co">#&gt; fracodeN06505                    0.20038    0.31560    0.63   0.5258   </span>
<span class="co">#&gt; fracodeN06516                    0.55455    0.29807    1.86   0.0635 . </span>
<span class="co">#&gt; fracodeN06524                    0.49429    0.31423    1.57   0.1164   </span>
<span class="co">#&gt; fracodeN06528                    0.75966    0.31060    2.45   0.0148 * </span>
<span class="co">#&gt; fracodeN06531                    0.36856    0.30155    1.22   0.2223   </span>
<span class="co">#&gt; fracodeN06862                    0.56932    0.29293    1.94   0.0526 . </span>
<span class="co">#&gt; fracodeN08002                    0.36779    0.26846    1.37   0.1714   </span>
<span class="co">#&gt; month                            0.17161    0.10865    1.58   0.1149   </span>
<span class="co">#&gt; aged                            -0.00336    0.00112   -3.00   0.0029 **</span>
<span class="co">#&gt; sexmale                          0.12352    0.09203    1.34   0.1802   </span>
<span class="co">#&gt; momage                          -0.01379    0.00973   -1.42   0.1570   </span>
<span class="co">#&gt; momeduPrimary (1-5y)            -0.13214    0.15225   -0.87   0.3859   </span>
<span class="co">#&gt; momeduSecondary (&gt;5y)            0.12632    0.16041    0.79   0.4314   </span>
<span class="co">#&gt; momheight                        0.00512    0.00919    0.56   0.5776   </span>
<span class="co">#&gt; hfiacatMildly Food Insecure      0.05804    0.19341    0.30   0.7643   </span>
<span class="co">#&gt; hfiacatModerately Food Insecure -0.01362    0.12887   -0.11   0.9159   </span>
<span class="co">#&gt; hfiacatSeverely Food Insecure   -0.13447    0.25418   -0.53   0.5970   </span>
<span class="co">#&gt; Nlt18                           -0.02557    0.04060   -0.63   0.5291   </span>
<span class="co">#&gt; Ncomp                            0.00179    0.00762    0.23   0.8145   </span>
<span class="co">#&gt; watmin                           0.01347    0.00861    1.57   0.1182   </span>
<span class="co">#&gt; elec                             0.08906    0.10700    0.83   0.4057   </span>
<span class="co">#&gt; floor                           -0.17763    0.17734   -1.00   0.3171   </span>
<span class="co">#&gt; walls                           -0.03001    0.21445   -0.14   0.8888   </span>
<span class="co">#&gt; roof                            -0.03716    0.49214   -0.08   0.9399   </span>
<span class="co">#&gt; asset_wardrobe                  -0.05754    0.13736   -0.42   0.6755   </span>
<span class="co">#&gt; asset_table                     -0.22079    0.12276   -1.80   0.0728 . </span>
<span class="co">#&gt; asset_chair                      0.28012    0.13750    2.04   0.0422 * </span>
<span class="co">#&gt; asset_khat                       0.02306    0.11766    0.20   0.8447   </span>
<span class="co">#&gt; asset_chouki                    -0.13943    0.14084   -0.99   0.3227   </span>
<span class="co">#&gt; asset_tv                         0.17723    0.12972    1.37   0.1726   </span>
<span class="co">#&gt; asset_refrig                     0.12613    0.23162    0.54   0.5863   </span>
<span class="co">#&gt; asset_bike                      -0.02568    0.10083   -0.25   0.7990   </span>
<span class="co">#&gt; asset_moto                      -0.32094    0.19944   -1.61   0.1083   </span>
<span class="co">#&gt; asset_sewmach                    0.05090    0.17795    0.29   0.7750   </span>
<span class="co">#&gt; asset_mobile                     0.01420    0.14972    0.09   0.9245   </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 0.984 on 447 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.129,  Adjusted R-squared:  0.0277 </span>
<span class="co">#&gt; F-statistic: 1.27 on 52 and 447 DF,  p-value: 0.104</span></code></pre></div>
<p>We can assess how well the model fits the data by comparing the predictions of
the linear model to the true outcomes observed in the data set. This is the well
known (and standard) mean squared error. We can extract that from the <code>lm</code> model
object as follows:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">err</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">lm_mod</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.86568</span></code></pre></div>
<p>The mean squared error is 0.86568. There is an important problem that arises
when we assess the model in this way - that is, we have trained our linear
regression model on the full data set and assessed the error on the full data
set, using up all of our data. We, of course, are generally not interested in
how well the model explains variation in the observed data; rather, we are
interested in how the explanation provided by the model generalizes to a target
population from which the sample is presumably derived. Having used all of our
available data, we cannot honestly evaluate how well the model fits (and thus
explains) variation at the population level.</p>
<p>To resolve this issue, cross-validation allows for a particular procedure (e.g.,
linear regression) to be implemented over subsets of the data, evaluating how
well the procedure fits on a testing (“validation”) set, thereby providing an
honest evaluation of the error.</p>
<p>We can easily add cross-validation to our linear regression procedure using
<code>origami</code>. First, let us define a new function to perform linear regression on a
specific partition of the data (called a “fold”):</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">cv_lm</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">fold</span>, <span class="va">data</span>, <span class="va">reg_form</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># get name and index of outcome variable from regression formula</span>
  <span class="va">out_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_split.html">str_split</a></span><span class="op">(</span><span class="va">reg_form</span>, <span class="st">" "</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>
  <span class="va">out_var_ind</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">==</span> <span class="va">out_var</span><span class="op">)</span><span class="op">)</span>

  <span class="co"># split up data into training and validation sets</span>
  <span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">training</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>

  <span class="co"># fit linear model on training set and predict on validation set</span>
  <span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="va">reg_form</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span>
  <span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">valid_data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">valid_data</span><span class="op">)</span>

  <span class="co"># capture results to be returned as output</span>
  <span class="va">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
    coef <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
    SE <span class="op">=</span> <span class="op">(</span><span class="va">preds</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">[</span>, <span class="va">out_var_ind</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span>
  <span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Our <code>cv_lm</code> function is rather simple: we merely split the available data into a
training and validation sets (using the eponymous functions provided in
<code>origami</code>) fit the linear model on the training set, and evaluate the model on
the validation set. This is a simple example of what <code>origami</code> considers to be
<code>cv_fun</code> — functions for using cross-validation to perform a particular routine
over an input data set. Having defined such a function, we can simply generate a
set of partitions using <code>origami</code>’s <code>make_folds</code> function, and apply our <code>cv_lm</code>
function over the resultant <code>folds</code> object. Below, we replicate the
re-substitution estimate of the error — we did this “by hand” above — using
the functions <code>make_folds</code> and <code>cv_lm</code>.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># re-substitution estimate</span>
<span class="va">resub</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span><span class="va">washb_data</span>, fold_fun <span class="op">=</span> <span class="va">folds_resubstitution</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="va">resub_results</span> <span class="op">&lt;-</span> <span class="fu">cv_lm</span><span class="op">(</span>fold <span class="op">=</span> <span class="va">resub</span>, data <span class="op">=</span> <span class="va">washb_data</span>, reg_form <span class="op">=</span> <span class="st">"whz ~ ."</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">resub_results</span><span class="op">$</span><span class="va">SE</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.86568</span></code></pre></div>
<p>This (nearly) matches the estimate of the error that we obtained above.</p>
<p>We can more honestly evaluate the error by V-fold cross-validation, which
partitions the data into <span class="math inline">\(v\)</span> subsets, fitting the model on <span class="math inline">\(v - 1\)</span> of the
subsets and evaluating on the subset that was held out for testing. This is
repeated such that each subset is used for validation. We can easily apply our
<code>cv_lm</code> function using <code>origami</code>’s <code>cross_validate</code> (n.b., by default this
performs 10-fold cross-validation):</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># cross-validated estimate</span>
<span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>
<span class="va">cvlm_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate</a></span><span class="op">(</span>
  cv_fun <span class="op">=</span> <span class="va">cv_lm</span>, folds <span class="op">=</span> <span class="va">folds</span>, data <span class="op">=</span> <span class="va">washb_data</span>, reg_form <span class="op">=</span> <span class="st">"whz ~ ."</span>,
  use_future <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">cvlm_results</span><span class="op">$</span><span class="va">SE</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">#&gt; [1] 1.35</span></code></pre></div>
<p>Having performed 10-fold cross-validation, we quickly notice that our previous
estimate of the model error (by resubstitution) was a bit optimistic. The honest
estimate of the error is larger!</p>
</div>
<div id="cross-validation-with-random-forests" class="section level3">
<h3>
<span class="header-section-number">4.7.2</span> Cross-validation with random forests<a class="anchor" aria-label="anchor" href="#cross-validation-with-random-forests"><i class="fas fa-link"></i></a>
</h3>
<p>To examine <code>origami</code> further, let us return to our example analysis using the
WASH data set. Here, we will write a new <code>cv_fun</code> type object. As an example, we
will use Breiman’s <code>randomForest</code> <span class="citation">(Breiman <a href="references.html#ref-breiman2001random" role="doc-biblioref">2001</a>)</span>:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># make sure to load the package!</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.stat.berkeley.edu/~breiman/RandomForests/">randomForest</a></span><span class="op">)</span>

<span class="va">cv_rf</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">fold</span>, <span class="va">data</span>, <span class="va">reg_form</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># get name and index of outcome variable from regression formula</span>
  <span class="va">out_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_split.html">str_split</a></span><span class="op">(</span><span class="va">reg_form</span>, <span class="st">" "</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>
  <span class="va">out_var_ind</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">==</span> <span class="va">out_var</span><span class="op">)</span><span class="op">)</span>

  <span class="co"># define training and validation sets based on input object of class "folds"</span>
  <span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">training</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>

  <span class="co"># fit Random Forest regression on training set and predict on holdout set</span>
  <span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="va">reg_form</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span>
  <span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">valid_data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">valid_data</span><span class="op">)</span>

  <span class="co"># define output object to be returned as list (for flexibility)</span>
  <span class="va">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
    coef <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">mod</span><span class="op">$</span><span class="va">coefs</span><span class="op">)</span>,
    SE <span class="op">=</span> <span class="op">(</span><span class="op">(</span><span class="va">preds</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">[</span>, <span class="va">out_var_ind</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
  <span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Above, in writing our <code>cv_rf</code> function to cross-validate <code>randomForest</code>, we used
our previous function <code>cv_lm</code> as an example. For now, individual <code>cv_fun</code> must
be written by hand; however, in future releases, a wrapper may be available to
support auto-generating <code>cv_fun</code>s to be used with <code>origami</code>.</p>
<p>Below, we use <code>cross_validate</code> to apply our new <code>cv_rf</code> function over the <code>folds</code>
object generated by <code>make_folds</code>.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># now, let's cross-validate...</span>
<span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>
<span class="va">cvrf_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate</a></span><span class="op">(</span>
  cv_fun <span class="op">=</span> <span class="va">cv_rf</span>, folds <span class="op">=</span> <span class="va">folds</span>,
  data <span class="op">=</span> <span class="va">washb_data</span>, reg_form <span class="op">=</span> <span class="st">"whz ~ ."</span>,
  use_future <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">cvrf_results</span><span class="op">$</span><span class="va">SE</span><span class="op">)</span>
<span class="co">#&gt; [1] 1.0271</span></code></pre></div>
<p>Using 10-fold cross-validation (the default), we obtain an honest estimate of
the prediction error of random forests. From this, we gather that the use of
<code>origami</code>’s <code>cross_validate</code> procedure can be generalized to arbitrary estimation
techniques, given availability of an appropriate <code>cv_fun</code> function.</p>
</div>
<div id="cross-validation-with-arima" class="section level3">
<h3>
<span class="header-section-number">4.7.3</span> Cross-validation with ARIMA<a class="anchor" aria-label="anchor" href="#cross-validation-with-arima"><i class="fas fa-link"></i></a>
</h3>
<p>Cross-validation can also be used for forecast model selection in a time series
setting. Here, the partitioning scheme mirrors the application of the
forecasting model: we’ll train the data on past observations (either all
available or a recent subset), and then use the ARIMA (AutoRegressive
Integrated Moving Average) model fit to predict the next few observations. We
consider the <code>AirPassengers</code> dataset again, a monthly time series of passenger
air traffic in thousands of people.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">AirPassengers</span><span class="op">)</span>
<span class="fu"><a href="https://docs.ropensci.org/skimr/reference/print.html">print</a></span><span class="op">(</span><span class="va">AirPassengers</span><span class="op">)</span>
<span class="co">#&gt;      Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec</span>
<span class="co">#&gt; 1949 112 118 132 129 121 135 148 148 136 119 104 118</span>
<span class="co">#&gt; 1950 115 126 141 135 125 149 170 170 158 133 114 140</span>
<span class="co">#&gt; 1951 145 150 178 163 172 178 199 199 184 162 146 166</span>
<span class="co">#&gt; 1952 171 180 193 181 183 218 230 242 209 191 172 194</span>
<span class="co">#&gt; 1953 196 196 236 235 229 243 264 272 237 211 180 201</span>
<span class="co">#&gt; 1954 204 188 235 227 234 264 302 293 259 229 203 229</span>
<span class="co">#&gt; 1955 242 233 267 269 270 315 364 347 312 274 237 278</span>
<span class="co">#&gt; 1956 284 277 317 313 318 374 413 405 355 306 271 306</span>
<span class="co">#&gt; 1957 315 301 356 348 355 422 465 467 404 347 305 336</span>
<span class="co">#&gt; 1958 340 318 362 348 363 435 491 505 404 359 310 337</span>
<span class="co">#&gt; 1959 360 342 406 396 420 472 548 559 463 407 362 405</span>
<span class="co">#&gt; 1960 417 391 419 461 472 535 622 606 508 461 390 432</span></code></pre></div>
<p>Suppose we want to pick between two forecasting models with different <code>arima</code>
configurations. We can do that by evaluating their forecasting performance.
First, we set up the appropriate cross-validation scheme for time-series.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span><span class="va">AirPassengers</span>,
  fold_fun <span class="op">=</span> <span class="va">folds_rolling_origin</span>,
  first_window <span class="op">=</span> <span class="fl">36</span>, validation_size <span class="op">=</span> <span class="fl">24</span>, batch <span class="op">=</span> <span class="fl">10</span>
<span class="op">)</span>

<span class="co"># How many folds where generated?</span>
<span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">folds</span><span class="op">)</span>
<span class="co">#&gt; [1] 9</span>

<span class="co"># Examine the first 2 folds.</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
<p>By default, <code>folds_rolling_origin</code> will increase the size of the training set by
one time point each fold. Had we followed the default option, we would have 85
folds to train! Luckily, we can pass the <code>batch</code> as option to
<code>folds_rolling_origin</code> that tells it to increase the size of the training set by
10 points each iteration. Since we want to forecast the immediate next point,
<code>gap</code> argument remains the default (0).</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># make sure to load the package!</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://pkg.robjhyndman.com/forecast/">forecast</a></span><span class="op">)</span>

<span class="co"># function to calculate cross-validated squared error</span>
<span class="va">cv_forecasts</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">fold</span>, <span class="va">data</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># Get training and validation data</span>
  <span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">training</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
  <span class="va">valid_size</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">valid_data</span><span class="op">)</span>

  <span class="va">train_ts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/ts.html">ts</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log10</a></span><span class="op">(</span><span class="va">train_data</span><span class="op">)</span>, frequency <span class="op">=</span> <span class="fl">12</span><span class="op">)</span>

  <span class="co"># First arima model</span>
  <span class="va">arima_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/arima.html">arima</a></span><span class="op">(</span><span class="va">train_ts</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,
    seasonal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
      order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,
      period <span class="op">=</span> <span class="fl">12</span>
    <span class="op">)</span>
  <span class="op">)</span>
  <span class="va">raw_arima_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">arima_fit</span>, n.ahead <span class="op">=</span> <span class="va">valid_size</span><span class="op">)</span>
  <span class="va">arima_pred</span> <span class="op">&lt;-</span> <span class="fl">10</span><span class="op">^</span><span class="va">raw_arima_pred</span><span class="op">$</span><span class="va">pred</span>
  <span class="va">arima_MSE</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">arima_pred</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>

  <span class="co"># Second arima model</span>
  <span class="va">arima_fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/arima.html">arima</a></span><span class="op">(</span><span class="va">train_ts</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,
    seasonal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
      order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,
      period <span class="op">=</span> <span class="fl">12</span>
    <span class="op">)</span>
  <span class="op">)</span>
  <span class="va">raw_arima_pred2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">arima_fit2</span>, n.ahead <span class="op">=</span> <span class="va">valid_size</span><span class="op">)</span>
  <span class="va">arima_pred2</span> <span class="op">&lt;-</span> <span class="fl">10</span><span class="op">^</span><span class="va">raw_arima_pred2</span><span class="op">$</span><span class="va">pred</span>
  <span class="va">arima_MSE2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">arima_pred2</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>

  <span class="va">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
    fold <span class="op">=</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">fold_index</a></span><span class="op">(</span><span class="op">)</span>,
    arima <span class="op">=</span> <span class="va">arima_MSE</span>, arima2 <span class="op">=</span> <span class="va">arima_MSE2</span>
  <span class="op">)</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">mses</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate</a></span><span class="op">(</span>
  cv_fun <span class="op">=</span> <span class="va">cv_forecasts</span>, folds <span class="op">=</span> <span class="va">folds</span>, data <span class="op">=</span> <span class="va">AirPassengers</span>,
  use_future <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span>
<span class="va">mses</span><span class="op">$</span><span class="va">mse</span>
<span class="co">#&gt;   fold   arima  arima2</span>
<span class="co">#&gt; 1    1   68.21  137.28</span>
<span class="co">#&gt; 2    2  319.68  313.15</span>
<span class="co">#&gt; 3    3  578.35  713.36</span>
<span class="co">#&gt; 4    4  428.69  505.31</span>
<span class="co">#&gt; 5    5  407.33  371.27</span>
<span class="co">#&gt; 6    6  281.82  250.99</span>
<span class="co">#&gt; 7    7  827.56  910.12</span>
<span class="co">#&gt; 8    8 2099.59 2213.15</span>
<span class="co">#&gt; 9    9  398.37  293.38</span>
<span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colMeans</a></span><span class="op">(</span><span class="va">mses</span><span class="op">$</span><span class="va">mse</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"arima"</span>, <span class="st">"arima2"</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>
<span class="co">#&gt;  arima arima2 </span>
<span class="co">#&gt; 601.07 634.22</span></code></pre></div>
<p>The arima model with no AR component seems to be a better fit for this data.</p>
</div>
</div>
<div id="exercises" class="section level2">
<h2>
<span class="header-section-number">4.8</span> Exercises<a class="anchor" aria-label="anchor" href="#exercises"><i class="fas fa-link"></i></a>
</h2>
<div id="review-of-key-concepts" class="section level3">
<h3>
<span class="header-section-number">4.8.1</span> Review of key concepts<a class="anchor" aria-label="anchor" href="#review-of-key-concepts"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Compare and contrast V-fold cross-validation with resubstitution
cross-validation. What are some of the differences between the two methods?
How are they similar? Describe a scenario when you would use one over the
other.</p></li>
<li>
<p>What are the advantages and disadvantages of <span class="math inline">\(v\)</span>-fold CV relative to:</p>
<ol style="list-style-type: lower-alpha">
<li>holdout CV?</li>
<li>leave-one-out CV?</li>
</ol>
</li>
<li><p>Why can’t we use V-fold cross-validation for time-series data?</p></li>
<li><p>Would you use rolling window or origin for non-stationary time-series? Why?</p></li>
</ol>
</div>
<div id="ideas-in-action" class="section level3">
<h3>
<span class="header-section-number">4.8.2</span> Ideas in action<a class="anchor" aria-label="anchor" href="#ideas-in-action"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(Y\)</span> be a binary variable with <span class="math inline">\(P(Y=1 \mid W) = 0.01\)</span>. What kind of
cross-validation scheme should be used for a rare outcome? How can we do this
with the <code>origami</code> package?</p></li>
<li><p>Consider the WASH benefits dataset presented in this chapter. How can we
include cluster information into cross-validation? How can we do this with
the <code>origami</code> package?</p></li>
</ol>
</div>
<div id="advanced-topics" class="section level3">
<h3>
<span class="header-section-number">4.8.3</span> Advanced topics<a class="anchor" aria-label="anchor" href="#advanced-topics"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Think about a dataset with arbitrary spatial dependence, where we know
the extent of dependence, and groups formed by such dependence are clear
with no spillover effects. What kind of cross-validation can we use?</p></li>
<li><p>Continuing on the last problem, what kind of procedure, and cross-validation
method, can we use if the spatial dependence is not clearly defined as in the
previous problem?</p></li>
<li>
<p>Consider a classification problem with a large number of predictors. A
statistician proposes the following analysis:</p>
<ol style="list-style-type: lower-alpha">
<li>First screen the predictors, leaving only covariates with a strong
correlation with the class labels.</li>
<li>Fit some algorithm using only the subset of highly correlated covariates.</li>
<li>Use cross-validation to estimate the tuning parameters and the performance
of the proposed algorithm.</li>
</ol>
<p>Is this a correct application of cross-validation? Why?</p>
</li>
</ol>
<!--
## Appendix

### Exercise solutions
-->
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="data.html"><span class="header-section-number">3</span> The WASH Benefits Example Dataset</a></div>
<div class="next"><a href="sl3.html"><span class="header-section-number">5</span> Super (Machine) Learning</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#origami"><span class="header-section-number">4</span> Cross-validation</a></li>
<li><a class="nav-link" href="#learning-objectives-1">Learning Objectives</a></li>
<li><a class="nav-link" href="#introduction-1"><span class="header-section-number">4.1</span> Introduction</a></li>
<li>
<a class="nav-link" href="#background"><span class="header-section-number">4.2</span> Background</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#what-is-cross-validation"><span class="header-section-number">4.2.1</span> What is cross-validation?</a></li></ul>
</li>
<li><a class="nav-link" href="#roadmap-how-does-it-all-fit-together"><span class="header-section-number">4.3</span> Roadmap: How does it all fit together?</a></li>
<li><a class="nav-link" href="#example-cross-validation-and-prediction"><span class="header-section-number">4.4</span> Example: cross-validation and prediction</a></li>
<li>
<a class="nav-link" href="#cross-validation-schemes-in-origami"><span class="header-section-number">4.5</span> Cross-validation schemes in origami</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#wash-benefits-study-example">WASH Benefits study example</a></li>
<li><a class="nav-link" href="#cross-validation-for-i.i.d.-data"><span class="header-section-number">4.5.1</span> Cross-validation for i.i.d. data</a></li>
<li><a class="nav-link" href="#cross-validation-for-dependent-data"><span class="header-section-number">4.5.2</span> Cross-validation for dependent data</a></li>
<li><a class="nav-link" href="#airpassenger-example">AirPassenger Example</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#general-workflow-of-origami"><span class="header-section-number">4.6</span> General workflow of origami</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#define-folds">(1) Define folds</a></li>
<li><a class="nav-link" href="#define-fold-function">(2) Define fold function</a></li>
<li><a class="nav-link" href="#apply-cross_validate">(3) Apply cross_validate</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#cross-validation-in-action"><span class="header-section-number">4.7</span> Cross-validation in action</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#cross-validation-with-linear-regression"><span class="header-section-number">4.7.1</span> Cross-validation with linear regression</a></li>
<li><a class="nav-link" href="#cross-validation-with-random-forests"><span class="header-section-number">4.7.2</span> Cross-validation with random forests</a></li>
<li><a class="nav-link" href="#cross-validation-with-arima"><span class="header-section-number">4.7.3</span> Cross-validation with ARIMA</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#exercises"><span class="header-section-number">4.8</span> Exercises</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#review-of-key-concepts"><span class="header-section-number">4.8.1</span> Review of key concepts</a></li>
<li><a class="nav-link" href="#ideas-in-action"><span class="header-section-number">4.8.2</span> Ideas in action</a></li>
<li><a class="nav-link" href="#advanced-topics"><span class="header-section-number">4.8.3</span> Advanced topics</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/tlverse/tmlcimx2021-workshop/blob/master/05-origami.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/tlverse/tmlcimx2021-workshop/edit/master/05-origami.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Targeted Machine Learning with Big Data in the <code>tlverse</code></strong>: A Short Course for the Public Health and Epidemiology Program (PASPE) at the National Institute of Public Health in Mexico" was written by Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips. It was last built on updated: August 16, 2021.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
